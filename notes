Architecture Notes
Merchant Transaction Analytics 
Andrew Jarmin 

1. How I structured the backend
- The backend I used was solely built in Python using Flask API web framework and several Python libraries to make the application run smooth. I choose Flask API for this application project because I am more familiar with it, it is robust, and easy to use. I organized this API backend into three main sections: api, services, and data. With app.py being the entry point of the application at the root level of the backend directory and additional directories such as /utils and /tests. 

API (api/) handles HTTP concerns only, essentially the "request" traffic controller, this handles the ability to extract the query parameters and direct it to the right functions, returning JSON. There are 4 routes 
- route("/api/transactions") 
- route("/api/summary/mtd")
- route("/api/summary/monthly")
- route("/api/health")

Services (services/) contain the core business logic. The aggregator module (aggregator.py) exposes three functions: filter_transactions for applying filters, mtd_summary for month-to-date aggregation, and month_by_month_summary for historical monthly breakdowns. Having these functions in its own seperate module means it can be scaled up being able to add more functionality.

Data (data/) is a static JSON file containing 100 mock transactions. This file is generated by a standalone utility script in (/utils/generator.py) and loaded at runtime by the application entry point in app.py

app.py is the entrypoint into the application and wires everything together, this imports data and registers the api routes making it straightforward to swap in different data sources or functions. 


2. How I modeled the data
Each transaction is a JSON object with the following fields (camel case): 
- transactionId (string): A unique identifier in the format "T####-####-#######", generated to resemble real transaction IDs. 
- merchantId (string): Identifies the merchant, "M1" through "M5", kept this simple. 
- amount (float): Transaction amount rounded to two decimal points, example: 61.42
- cardBrand (string): One of four values: "Visa", "Mastercard", "Amex", or "Discover"
- status (string): "Approved" or "Declined" 
- declineReasonCode (string or null): A two digit code "01", "02", or "03" for declined transactions, and null for approed ones. 
    - "01": represents insufficient funds 
    - "02": represents invalid card
    - "03": represents suspected fraud
- transactionDate (string): An ISO 8601 timestamp used for date-based filtering and grouping in the format "YYYY-MM-DDTHH:MM:SS"

I chose JSON over CSV because it maps directly to Python dictionaries and being able to use the library JSONIFY makes it easy to work with JSON data sets. I am also very familiar with JSON datasets compared to CSV. 

3. How I approached filtering and aggregation

Filtering
The filter_transaction function ref:(backend/services/aggregator.py) takes a list of transactions and three optional parameters: cardBrand, status, and declineReasonCode. It loops through the list once and skips any transaction that doesn't match the active filters. If no filters are provided, all transactions pass through. 

Aggregation
There are two aggregation endpoints, both of which apply filters before aggregating: 
Month-to-Date (MTD) Summary: 
First it narrows the dataset to only transactions in the current calendar month, then applies any user filters (for ex: "Mastercard", "Approved") and then computes the totals: total transactions, approved count, declined count, dollar amounts, a breakdown by card brand, and a breakdown by decline reason code. 
Month-by-Month Summary: 
First applies filters to the full dataset, then group transactions by their year-month. Each month gets the same set of computed metric as the MTD summary. The results include a sortKey field (formatted as (YYY-MM)) so the frontend can sort months chronologically without having to parse display labels like "Jan 2025" 

3. Tradeoffs I made: 

